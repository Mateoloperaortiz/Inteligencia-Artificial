{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio 2 — Laberinto (Punto 2)\n",
        "\n",
        "En este notebook se resuelve el problema del laberinto con búsqueda informada usando una cola de prioridad y heurística de Manhattan.\n",
        "\n",
        "Incluye:\n",
        "- Implementación base (resolución del laberinto).\n",
        "- Análisis del efecto de cambiar la función de costo.\n",
        "- Manejo de múltiples salidas.\n",
        "- Prueba con un laberinto más grande y nuevos obstáculos, y discusión de limitaciones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import heapq\n",
        "import itertools\n",
        "from typing import List, Tuple, Dict, Optional, Callable\n",
        "\n",
        "Position = Tuple[int, int]\n",
        "Action = str  # 'Up', 'Down', 'Left', 'Right'\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, position: Position, parent: Optional['Node']=None, path_cost: float=0.0, action: Optional[Action]=None):\n",
        "        self.position = position\n",
        "        self.parent = parent\n",
        "        self.path_cost = path_cost\n",
        "        self.action = action\n",
        "\n",
        "    def __lt__(self, other: 'Node'):\n",
        "        # No depender de esta comparación en el heap; se usa un desempate explícito.\n",
        "        return self.path_cost < other.path_cost\n",
        "\n",
        "class Problem:\n",
        "    def __init__(self, maze: List[List[str]], start: Position, goals: List[Position],\n",
        "                 move_cost: Callable[[Position, Position, Action], float],\n",
        "                 actions: Optional[Dict[Tuple[int, int], Action]] = None):\n",
        "        self.maze = maze\n",
        "        self.start = start\n",
        "        self.goals = set(goals)\n",
        "        self.rows = len(maze)\n",
        "        self.cols = len(maze[0]) if self.rows > 0 else 0\n",
        "        # Movimientos por defecto: vectores y nombres\n",
        "        self.moves: Dict[Tuple[int, int], Action] = actions or {\n",
        "            (-1, 0): 'Up',\n",
        "            (1, 0): 'Down',\n",
        "            (0, -1): 'Left',\n",
        "            (0, 1): 'Right',\n",
        "        }\n",
        "        self.move_cost = move_cost\n",
        "\n",
        "    def in_bounds(self, pos: Position) -> bool:\n",
        "        r, c = pos\n",
        "        return 0 <= r < self.rows and 0 <= c < self.cols\n",
        "\n",
        "    def is_blocked(self, pos: Position) -> bool:\n",
        "        r, c = pos\n",
        "        return self.maze[r][c] == '#'\n",
        "\n",
        "    def is_goal(self, pos: Position) -> bool:\n",
        "        return pos in self.goals\n",
        "\n",
        "    def get_neighbors(self, pos: Position) -> List[Tuple[Position, Action]]:\n",
        "        neighbors: List[Tuple[Position, Action]] = []\n",
        "        for (dr, dc), action in self.moves.items():\n",
        "            nr, nc = pos[0] + dr, pos[1] + dc\n",
        "            npos = (nr, nc)\n",
        "            if self.in_bounds(npos) and not self.is_blocked(npos):\n",
        "                neighbors.append((npos, action))\n",
        "        return neighbors\n",
        "\n",
        "def manhattan(a: Position, b: Position) -> int:\n",
        "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
        "\n",
        "def reconstruct_path(node: Node) -> List[Tuple[Position, Optional[Action]]]:\n",
        "    path: List[Tuple[Position, Optional[Action]]] = []\n",
        "    while node is not None:\n",
        "        path.append((node.position, node.action))\n",
        "        node = node.parent\n",
        "    path.reverse()\n",
        "    return path\n",
        "\n",
        "def min_heuristic_to_goals(pos: Position, goals: List[Position], heuristic: Callable[[Position, Position], float]) -> float:\n",
        "    return min(heuristic(pos, g) for g in goals)\n",
        "\n",
        "def compute_path_cost(path: List[Tuple[Position, Optional[Action]]], move_cost: Callable[[Position, Position, Action], float]) -> float:\n",
        "    total = 0.0\n",
        "    for i in range(1, len(path)):\n",
        "        prev_pos = path[i-1][0]\n",
        "        pos, action = path[i]\n",
        "        if action is None:\n",
        "            continue\n",
        "        total += move_cost(prev_pos, pos, action)\n",
        "    return total\n",
        "\n",
        "def informed_search(maze: List[List[str]], start: Position, goals: List[Position],\n",
        "                    heuristic: Callable[[Position, Position], float],\n",
        "                    move_cost: Callable[[Position, Position, Action], float],\n",
        "                    a_star: bool = True) -> Optional[List[Tuple[Position, Optional[Action]]]]:\n",
        "    \"\"\"\n",
        "    Si a_star=True, usa f(n) = g(n) + h(n) (A*). Si False, usa solo h(n) (Greedy Best-First).\n",
        "    Para múltiples metas usa h(n) = min_g h(n, g).\n",
        "    \"\"\"\n",
        "    problem = Problem(maze, start, goals, move_cost)\n",
        "\n",
        "    start_node = Node(start, path_cost=0.0, action=None, parent=None)\n",
        "    # prioridad: f = g + h (o solo h si greedy). Usar un contador para desempate estable.\n",
        "    counter = itertools.count()\n",
        "    h0 = min_heuristic_to_goals(start, list(problem.goals), heuristic)\n",
        "    start_priority = (start_node.path_cost + h0) if a_star else h0\n",
        "    frontier: List[Tuple[float, int, Node]] = [(start_priority, next(counter), start_node)]\n",
        "    heapq.heapify(frontier)\n",
        "\n",
        "    reached: Dict[Position, float] = {start: 0.0}\n",
        "\n",
        "    while frontier:\n",
        "        _, _, node = heapq.heappop(frontier)\n",
        "        if problem.is_goal(node.position):\n",
        "            return reconstruct_path(node)\n",
        "\n",
        "        for neighbor_pos, action in problem.get_neighbors(node.position):\n",
        "            step_cost = move_cost(node.position, neighbor_pos, action)\n",
        "            new_cost = node.path_cost + step_cost\n",
        "            if neighbor_pos not in reached or new_cost < reached[neighbor_pos]:\n",
        "                reached[neighbor_pos] = new_cost\n",
        "                neighbor_node = Node(neighbor_pos, parent=node, path_cost=new_cost, action=action)\n",
        "                h = min_heuristic_to_goals(neighbor_pos, list(problem.goals), heuristic)\n",
        "                priority = (new_cost + h) if a_star else h\n",
        "                heapq.heappush(frontier, (priority, next(counter), neighbor_node))\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((1, 1), None),\n",
              " ((2, 1), 'Down'),\n",
              " ((2, 2), 'Right'),\n",
              " ((2, 3), 'Right'),\n",
              " ((3, 3), 'Down'),\n",
              " ((3, 4), 'Right'),\n",
              " ((3, 5), 'Right'),\n",
              " ((2, 5), 'Up'),\n",
              " ((1, 5), 'Up'),\n",
              " ((1, 6), 'Right')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Laberinto base del enunciado\n",
        "maze = [\n",
        "    [\"#\", \"#\", \"#\", \"#\", \"#\", \"#\", \"#\",\"#\"],\n",
        "    [\"#\", \"S\", \"#\", \" \", \"#\", \" \", \"E\",\"#\"],\n",
        "    [\"#\", \" \", \" \", \" \", \"#\", \" \", \" \",\"#\"],\n",
        "    [\"#\", \" \", \"#\", \" \", \" \", \" \", \"#\",\"#\"],\n",
        "    [\"#\", \"#\", \"#\", \"#\", \"#\", \"#\", \"#\",\"#\"],\n",
        "    [\"#\", \"#\", \"#\", \"#\", \"#\", \"#\", \"#\",\"#\"]\n",
        "]\n",
        "\n",
        "# Ubicar S y E\n",
        "start = None\n",
        "goals = []\n",
        "for r, row in enumerate(maze):\n",
        "    for c, val in enumerate(row):\n",
        "        if val == 'S':\n",
        "            start = (r, c)\n",
        "        if val == 'E':\n",
        "            goals.append((r, c))\n",
        "\n",
        "assert start is not None and goals, \"No se encontraron S o E en el laberinto\"\n",
        "\n",
        "# Costo uniforme por paso\n",
        "uniform_cost = lambda a, b, action: 1.0\n",
        "\n",
        "path = informed_search(maze, start, goals, heuristic=manhattan, move_cost=uniform_cost, a_star=True)\n",
        "path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########\n",
            "#S# #.E#\n",
            "#...#. #\n",
            "# #...##\n",
            "########\n",
            "########\n",
            "Acciones: ['Down', 'Right', 'Right', 'Down', 'Right', 'Right', 'Up', 'Up', 'Right']\n"
          ]
        }
      ],
      "source": [
        "def pretty_print_path(maze, path):\n",
        "    # clonar\n",
        "    drawn = [row[:] for row in maze]\n",
        "    for (r, c), action in path[1:-1]:\n",
        "        if drawn[r][c] == ' ':\n",
        "            drawn[r][c] = '.'\n",
        "    return '\\n'.join(''.join(row) for row in drawn)\n",
        "\n",
        "print(pretty_print_path(maze, path))\n",
        "print(\"Acciones:\", [a for (_, a) in path if a is not None])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) ¿Cómo cambia el comportamiento si cambiamos la función de costo?\n",
        "\n",
        "A continuación comparamos:\n",
        "- Costo uniforme por paso (1 por movimiento).\n",
        "- Costo que penaliza moverse verticalmente (por ejemplo, `Up`/`Down` valen 2 y `Left`/`Right` valen 1).\n",
        "\n",
        "Esto afecta la ruta elegida por A*, ya que `g(n)` cambia y el algoritmo buscará caminos que minimicen el costo acumulado, no sólo la cantidad de pasos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ruta con costo uniforme:\n",
            "########\n",
            "#S# #.E#\n",
            "#...#. #\n",
            "# #...##\n",
            "########\n",
            "########\n",
            "Costo total: 9.0\n",
            "Acciones: ['Down', 'Right', 'Right', 'Down', 'Right', 'Right', 'Up', 'Up', 'Right']\n",
            "\n",
            "Ruta con costo penalizado (vertical=2):\n",
            "########\n",
            "#S# # E#\n",
            "#...#..#\n",
            "# #...##\n",
            "########\n",
            "########\n",
            "Costo total: 13.0\n",
            "Acciones: ['Down', 'Right', 'Right', 'Down', 'Right', 'Right', 'Up', 'Right', 'Up']\n"
          ]
        }
      ],
      "source": [
        "# Costo no uniforme: penaliza vertical\n",
        "penalized_cost = lambda a, b, action: 2.0 if action in ('Up', 'Down') else 1.0\n",
        "\n",
        "path_uniform = informed_search(maze, start, goals, heuristic=manhattan, move_cost=uniform_cost, a_star=True)\n",
        "path_penalized = informed_search(maze, start, goals, heuristic=manhattan, move_cost=penalized_cost, a_star=True)\n",
        "\n",
        "print('Ruta con costo uniforme:')\n",
        "print(pretty_print_path(maze, path_uniform))\n",
        "print('Costo total:', compute_path_cost(path_uniform, uniform_cost) if path_uniform else None)\n",
        "print('Acciones:', [a for (_, a) in path_uniform if a is not None] if path_uniform else None)\n",
        "\n",
        "print('\\nRuta con costo penalizado (vertical=2):')\n",
        "print(pretty_print_path(maze, path_penalized))\n",
        "print('Costo total:', compute_path_cost(path_penalized, penalized_cost) if path_penalized else None)\n",
        "print('Acciones:', [a for (_, a) in path_penalized if a is not None] if path_penalized else None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Múltiples salidas\n",
        "\n",
        "La implementación ya acepta una lista de metas `goals`. La prioridad se calcula con respecto a la meta más cercana (por Manhattan) desde el nodo actual.\n",
        "\n",
        "Ejemplo: añadimos otra `E` y observamos que el algoritmo puede llegar a cualquiera de ellas, priorizando la más cercana según heurística.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########\n",
            "#S# # E#\n",
            "#...#.E#\n",
            "# #...##\n",
            "########\n",
            "########\n",
            "Acciones: ['Down', 'Right', 'Right', 'Down', 'Right', 'Right', 'Up', 'Right']\n"
          ]
        }
      ],
      "source": [
        "maze_multi = [row[:] for row in maze]\n",
        "maze_multi[2][6] = 'E'  # nueva salida\n",
        "\n",
        "# Recalcular metas\n",
        "goals_multi = []\n",
        "for r, row in enumerate(maze_multi):\n",
        "    for c, val in enumerate(row):\n",
        "        if val == 'E':\n",
        "            goals_multi.append((r, c))\n",
        "\n",
        "path_multi = informed_search(maze_multi, start, goals_multi, heuristic=manhattan, move_cost=uniform_cost, a_star=True)\n",
        "print(pretty_print_path(maze_multi, path_multi))\n",
        "print('Acciones:', [a for (_, a) in path_multi if a is not None])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Laberinto más grande y nuevos obstáculos\n",
        "\n",
        "Agregamos celdas con un obstáculo adicional: por ejemplo, agua `~` que tiene costo 3 por paso (pero no bloquea), y paredes `#` que bloquean. Mostramos la ruta y discutimos limitaciones: tamaño del espacio de estados, consistencia de la heurística, y posibles trade-offs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud del camino: 25\n",
            "#####################\n",
            "#S...~.... # ....E  #\n",
            "# ### ###.###.### ## \n",
            "#   #   ~...#.    ## \n",
            "### # #####.#.### ## \n",
            "#   #     #...#   ## \n",
            "# ### ### ##### ###  \n",
            "#   ~   #     ~  ##  \n",
            "##### # ### #### ##  \n",
            "#     #   ~   #  ##  \n",
            "#####################\n",
            "Costo total: 26.0\n"
          ]
        }
      ],
      "source": [
        "# Laberinto más grande con agua (~)\n",
        "maze_big_rows = [\n",
        "    \"#####################\",\n",
        "    \"#S   ~     #     E  #\",\n",
        "    \"# ### ### ### ### ##\",\n",
        "    \"#   #   ~   #     ##\",\n",
        "    \"### # ##### # ### ##\",\n",
        "    \"#   #     #   #   ##\",\n",
        "    \"# ### ### ##### ###\",\n",
        "    \"#   ~   #     ~  ##\",\n",
        "    \"##### # ### #### ##\",\n",
        "    \"#     #   ~   #  ##\",\n",
        "    \"#####################\",\n",
        "]\n",
        "max_width = max(len(r) for r in maze_big_rows)\n",
        "maze_big = [list(r.ljust(max_width)) for r in maze_big_rows]\n",
        "\n",
        "# localizar S y E\n",
        "start_big = None\n",
        "goals_big = []\n",
        "for r, row in enumerate(maze_big):\n",
        "    for c, val in enumerate(row):\n",
        "        if val == 'S':\n",
        "            start_big = (r, c)\n",
        "        if val == 'E':\n",
        "            goals_big.append((r, c))\n",
        "\n",
        "assert start_big is not None and goals_big\n",
        "\n",
        "# costo: 1 para espacio, 3 para agua, bloqueado para '#'\n",
        "def terrain_cost(a: Position, b: Position, action: Action) -> float:\n",
        "    r, c = b\n",
        "    cell = maze_big[r][c]\n",
        "    if cell == '~':\n",
        "        return 3.0\n",
        "    return 1.0\n",
        "\n",
        "path_big = informed_search(maze_big, start_big, goals_big, heuristic=manhattan, move_cost=terrain_cost, a_star=True)\n",
        "print('Longitud del camino:', len(path_big) if path_big else None)\n",
        "print(pretty_print_path(maze_big, path_big) if path_big else 'No hay camino')\n",
        "print('Costo total:', compute_path_cost(path_big, lambda a,b,act: terrain_cost(a,b,act)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comentarios sobre limitaciones\n",
        "- Con laberintos más grandes, el número de estados crece y A* puede requerir mucha memoria/tiempo si la heurística no es muy informativa.\n",
        "- La heurística Manhattan es admisible y consistente cuando solo hay movimientos ortogonales y costos uniformes. Si hay costos variables (p. ej. agua), sigue siendo admisible si no sobrestima el costo real más bajo; puede volverse poco informativa, aumentando la exploración.\n",
        "- Obstáculos con alto costo pero transitables (como `~`) pueden hacer que A* explore muchos desvíos; considerar heurísticas ponderadas o infladas, o variantes como D* para entornos con costos dinámicos.\n",
        "- Para múltiples metas, priorizar por la más cercana es efectivo, pero si los costos del terreno varían mucho, una heurística mejor sería la distancia ponderada estimada (difícil sin conocimiento previo).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparación A* vs Greedy Best-First\n",
        "\n",
        "Comparamos A* (usa costo acumulado + heurística) contra Greedy Best-First (solo heurística) en el laberinto base con costo uniforme, para observar diferencias en costo y secuencia de acciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A* (g+h) — costo, pasos y acciones:\n",
            "########\n",
            "#S# #.E#\n",
            "#...#. #\n",
            "# #...##\n",
            "########\n",
            "########\n",
            "Costo: 9.0\n",
            "Pasos: 9\n",
            "Acciones: ['Down', 'Right', 'Right', 'Down', 'Right', 'Right', 'Up', 'Up', 'Right']\n",
            "\n",
            "Greedy Best-First (h) — costo, pasos y acciones:\n",
            "########\n",
            "#S# #.E#\n",
            "#...#. #\n",
            "# #...##\n",
            "########\n",
            "########\n",
            "Costo: 9.0\n",
            "Pasos: 9\n",
            "Acciones: ['Down', 'Right', 'Right', 'Down', 'Right', 'Right', 'Up', 'Up', 'Right']\n"
          ]
        }
      ],
      "source": [
        "path_astar = informed_search(maze, start, goals, heuristic=manhattan, move_cost=uniform_cost, a_star=True)\n",
        "path_greedy = informed_search(maze, start, goals, heuristic=manhattan, move_cost=uniform_cost, a_star=False)\n",
        "\n",
        "print('A* (g+h) — costo, pasos y acciones:')\n",
        "print(pretty_print_path(maze, path_astar))\n",
        "print('Costo:', compute_path_cost(path_astar, uniform_cost))\n",
        "print('Pasos:', len(path_astar)-1)\n",
        "print('Acciones:', [a for (_, a) in path_astar if a is not None])\n",
        "\n",
        "print('\\nGreedy Best-First (h) — costo, pasos y acciones:')\n",
        "print(pretty_print_path(maze, path_greedy))\n",
        "print('Costo:', compute_path_cost(path_greedy, uniform_cost))\n",
        "print('Pasos:', len(path_greedy)-1)\n",
        "print('Acciones:', [a for (_, a) in path_greedy if a is not None])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
